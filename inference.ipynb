{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Install your requirements"
      ],
      "metadata": {
        "id": "080IMPVOwmLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import torch\n",
        "import pycocotools._mask as _mask\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd"
      ],
      "metadata": {
        "id": "o_vRKro4KXn8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "\n",
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from skimage.measure import find_contours\n",
        "from skimage.measure import label\n",
        "from scipy.ndimage.morphology import binary_fill_holes\n",
        "from skimage.morphology import dilation, erosion\n",
        "from itertools import groupby"
      ],
      "metadata": {
        "id": "h_UNz3abIyt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62090f9b-3635-484b-ebff-bd0a7e59905b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 274 kB 5.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=b04aaefb6f5356ebe024fc2138e27d145e055ab5f32aa907ac9ceae4ccc3ad41\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Collecting detectron2\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 791 kB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.3)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20211023.tar.gz (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 35.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Collecting regex>=2020.1.8\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 31.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 45.3 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.24)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20211023-py3-none-any.whl size=60947 sha256=d38d66c1224223ba5d07b1f04c7f7d03808e8e44fb932ec38e7259fc95295178\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/98/fc/252d62cab6263c719120e06b28f3378af59b52ce7a20e81852\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=de1151f7be247ac6d83d9cb19614bdf7611ea3bac7fe384fccbbcf483770af20\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, regex, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "Successfully installed antlr4-python3-runtime-4.8 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20211023 hydra-core-1.1.1 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.1.1 pathspec-0.9.0 portalocker-2.3.2 regex-2021.11.10 typed-ast-1.5.1 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Wget testing data and pretrained weight"
      ],
      "metadata": {
        "id": "XWxALMi1wvTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the testing data\n",
        "gdd.download_file_from_google_drive(file_id='1nEJ7NTtHcCHNQqUXaoPk55VH3Uwh4QGG',\n",
        "                  dest_path='./dataset.zip',\n",
        "                  unzip=True)"
      ],
      "metadata": {
        "id": "gnf5W6b8Gns2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc542baa-b022-49dc-b907-de4c65e9ecbb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1nEJ7NTtHcCHNQqUXaoPk55VH3Uwh4QGG into ./dataset.zip... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load my pretrained model weights\n",
        "gdd.download_file_from_google_drive(file_id='12j_E_J-j2RSC0hGzapnNp2oZ87IisneI',\n",
        "                  dest_path='./model_final.pth',\n",
        "                  unzip=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnNyG93uxUR8",
        "outputId": "a886f75d-a881-480c-9a92-f6c7bcd31fce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 12j_E_J-j2RSC0hGzapnNp2oZ87IisneI into ./model_final.pth... Done.\n",
            "Unzipping...Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Register dataset and modify config file"
      ],
      "metadata": {
        "id": "TRU4lnBBro6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register dataset\n",
        "inpath = \"/content/dataset/train/\"  # the train folder download from kaggle\n",
        "images_name = listdir(inpath)\n",
        "if not os.path.isdir('/content/dataset/train_new'):\n",
        "    os.mkdir('/content/dataset/train_new')\n",
        "outpath = \"/content/dataset/train_new/\"  # the folder putting all nuclei image\n",
        "for f in images_name:\n",
        "    image = listdir(inpath + f + \"/images/\")\n",
        "    shutil.copyfile(inpath + f + \"/images/\" + image[0], outpath + image[0])\n",
        "DatasetCatalog.clear()\n",
        "register_coco_instances(\"my_dataset\", {}, \"nucleus_cocoformat.json\", \"/content/dataset/train_new\")  \n",
        "\n",
        "# Modify the cofig file\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))  \n",
        "cfg.MODEL.WEIGHTS = \"/content/model_final.pth\"  \n",
        "cfg.OUTPUT_DIR = \"./output\"\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset\",)\n",
        "cfg.DATASETS.TEST = ()  \n",
        "cfg.DATALOADER.NUM_WORKERS = 2  \n",
        "cfg.SOLVER.IMS_PER_BATCH = 2  \n",
        "cfg.SOLVER.BASE_LR = 0.00025    \n",
        "cfg.SOLVER.MAX_ITER = 3000\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 2000\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "predictor = DefaultPredictor(cfg)\n",
        "print(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxJNBxg46sbm",
        "outputId": "928fb61b-a4a1-4ffd-c522-67b48a1973bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDNN_BENCHMARK: False\n",
            "DATALOADER:\n",
            "  ASPECT_RATIO_GROUPING: True\n",
            "  FILTER_EMPTY_ANNOTATIONS: True\n",
            "  NUM_WORKERS: 2\n",
            "  REPEAT_THRESHOLD: 0.0\n",
            "  SAMPLER_TRAIN: TrainingSampler\n",
            "DATASETS:\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000\n",
            "  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000\n",
            "  PROPOSAL_FILES_TEST: ()\n",
            "  PROPOSAL_FILES_TRAIN: ()\n",
            "  TEST: ()\n",
            "  TRAIN: ('my_dataset',)\n",
            "GLOBAL:\n",
            "  HACK: 1.0\n",
            "INPUT:\n",
            "  CROP:\n",
            "    ENABLED: False\n",
            "    SIZE: [0.9, 0.9]\n",
            "    TYPE: relative_range\n",
            "  FORMAT: BGR\n",
            "  MASK_FORMAT: polygon\n",
            "  MAX_SIZE_TEST: 1333\n",
            "  MAX_SIZE_TRAIN: 1333\n",
            "  MIN_SIZE_TEST: 800\n",
            "  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TRAIN_SAMPLING: choice\n",
            "  RANDOM_FLIP: horizontal\n",
            "MODEL:\n",
            "  ANCHOR_GENERATOR:\n",
            "    ANGLES: [[-90, 0, 90]]\n",
            "    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]\n",
            "    NAME: DefaultAnchorGenerator\n",
            "    OFFSET: 0.0\n",
            "    SIZES: [[32], [64], [128], [256], [512]]\n",
            "  BACKBONE:\n",
            "    FREEZE_AT: 2\n",
            "    NAME: build_resnet_fpn_backbone\n",
            "  DEVICE: cuda\n",
            "  FPN:\n",
            "    FUSE_TYPE: sum\n",
            "    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    NORM: \n",
            "    OUT_CHANNELS: 256\n",
            "  KEYPOINT_ON: False\n",
            "  LOAD_PROPOSALS: False\n",
            "  MASK_ON: True\n",
            "  META_ARCHITECTURE: GeneralizedRCNN\n",
            "  PANOPTIC_FPN:\n",
            "    COMBINE:\n",
            "      ENABLED: True\n",
            "      INSTANCES_CONFIDENCE_THRESH: 0.5\n",
            "      OVERLAP_THRESH: 0.5\n",
            "      STUFF_AREA_LIMIT: 4096\n",
            "    INSTANCE_LOSS_WEIGHT: 1.0\n",
            "  PIXEL_MEAN: [103.53, 116.28, 123.675]\n",
            "  PIXEL_STD: [57.375, 57.12, 58.395]\n",
            "  PROPOSAL_GENERATOR:\n",
            "    MIN_SIZE: 0\n",
            "    NAME: RPN\n",
            "  RESNETS:\n",
            "    DEFORM_MODULATED: False\n",
            "    DEFORM_NUM_GROUPS: 1\n",
            "    DEFORM_ON_PER_STAGE: [False, False, False, False]\n",
            "    DEPTH: 101\n",
            "    NORM: FrozenBN\n",
            "    NUM_GROUPS: 32\n",
            "    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']\n",
            "    RES2_OUT_CHANNELS: 256\n",
            "    RES5_DILATION: 1\n",
            "    STEM_OUT_CHANNELS: 64\n",
            "    STRIDE_IN_1X1: False\n",
            "    WIDTH_PER_GROUP: 8\n",
            "  RETINANET:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    FOCAL_LOSS_ALPHA: 0.25\n",
            "    FOCAL_LOSS_GAMMA: 2.0\n",
            "    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.4, 0.5]\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NORM: \n",
            "    NUM_CLASSES: 80\n",
            "    NUM_CONVS: 4\n",
            "    PRIOR_PROB: 0.01\n",
            "    SCORE_THRESH_TEST: 0.05\n",
            "    SMOOTH_L1_LOSS_BETA: 0.1\n",
            "    TOPK_CANDIDATES_TEST: 1000\n",
            "  ROI_BOX_CASCADE_HEAD:\n",
            "    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))\n",
            "    IOUS: (0.5, 0.6, 0.7)\n",
            "  ROI_BOX_HEAD:\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)\n",
            "    CLS_AGNOSTIC_BBOX_REG: False\n",
            "    CONV_DIM: 256\n",
            "    FC_DIM: 1024\n",
            "    NAME: FastRCNNConvFCHead\n",
            "    NORM: \n",
            "    NUM_CONV: 0\n",
            "    NUM_FC: 2\n",
            "    POOLER_RESOLUTION: 7\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "    TRAIN_ON_PRED_BOXES: False\n",
            "  ROI_HEADS:\n",
            "    BATCH_SIZE_PER_IMAGE: 128\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    IOU_LABELS: [0, 1]\n",
            "    IOU_THRESHOLDS: [0.5]\n",
            "    NAME: StandardROIHeads\n",
            "    NMS_THRESH_TEST: 0.5\n",
            "    NUM_CLASSES: 1\n",
            "    POSITIVE_FRACTION: 0.25\n",
            "    PROPOSAL_APPEND_GT: True\n",
            "    SCORE_THRESH_TEST: 0.5\n",
            "  ROI_KEYPOINT_HEAD:\n",
            "    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    MIN_KEYPOINTS_PER_IMAGE: 1\n",
            "    NAME: KRCNNConvDeconvUpsampleHead\n",
            "    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True\n",
            "    NUM_KEYPOINTS: 17\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  ROI_MASK_HEAD:\n",
            "    CLS_AGNOSTIC_MASK: False\n",
            "    CONV_DIM: 256\n",
            "    NAME: MaskRCNNConvUpsampleHead\n",
            "    NORM: \n",
            "    NUM_CONV: 4\n",
            "    POOLER_RESOLUTION: 14\n",
            "    POOLER_SAMPLING_RATIO: 0\n",
            "    POOLER_TYPE: ROIAlignV2\n",
            "  RPN:\n",
            "    BATCH_SIZE_PER_IMAGE: 256\n",
            "    BBOX_REG_LOSS_TYPE: smooth_l1\n",
            "    BBOX_REG_LOSS_WEIGHT: 1.0\n",
            "    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)\n",
            "    BOUNDARY_THRESH: -1\n",
            "    CONV_DIMS: [-1]\n",
            "    HEAD_NAME: StandardRPNHead\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']\n",
            "    IOU_LABELS: [0, -1, 1]\n",
            "    IOU_THRESHOLDS: [0.3, 0.7]\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NMS_THRESH: 0.7\n",
            "    POSITIVE_FRACTION: 0.5\n",
            "    POST_NMS_TOPK_TEST: 1000\n",
            "    POST_NMS_TOPK_TRAIN: 1000\n",
            "    PRE_NMS_TOPK_TEST: 1000\n",
            "    PRE_NMS_TOPK_TRAIN: 2000\n",
            "    SMOOTH_L1_BETA: 0.0\n",
            "  SEM_SEG_HEAD:\n",
            "    COMMON_STRIDE: 4\n",
            "    CONVS_DIM: 128\n",
            "    IGNORE_VALUE: 255\n",
            "    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']\n",
            "    LOSS_WEIGHT: 1.0\n",
            "    NAME: SemSegFPNHead\n",
            "    NORM: GN\n",
            "    NUM_CLASSES: 54\n",
            "  WEIGHTS: /content/model_final.pth\n",
            "OUTPUT_DIR: ./output\n",
            "SEED: -1\n",
            "SOLVER:\n",
            "  AMP:\n",
            "    ENABLED: False\n",
            "  BASE_LR: 0.00025\n",
            "  BIAS_LR_FACTOR: 1.0\n",
            "  CHECKPOINT_PERIOD: 5000\n",
            "  CLIP_GRADIENTS:\n",
            "    CLIP_TYPE: value\n",
            "    CLIP_VALUE: 1.0\n",
            "    ENABLED: False\n",
            "    NORM_TYPE: 2.0\n",
            "  GAMMA: 0.1\n",
            "  IMS_PER_BATCH: 2\n",
            "  LR_SCHEDULER_NAME: WarmupMultiStepLR\n",
            "  MAX_ITER: 3000\n",
            "  MOMENTUM: 0.9\n",
            "  NESTEROV: False\n",
            "  REFERENCE_WORLD_SIZE: 0\n",
            "  STEPS: (210000, 250000)\n",
            "  WARMUP_FACTOR: 0.001\n",
            "  WARMUP_ITERS: 1000\n",
            "  WARMUP_METHOD: linear\n",
            "  WEIGHT_DECAY: 0.0001\n",
            "  WEIGHT_DECAY_BIAS: None\n",
            "  WEIGHT_DECAY_NORM: 0.0\n",
            "TEST:\n",
            "  AUG:\n",
            "    ENABLED: False\n",
            "    FLIP: True\n",
            "    MAX_SIZE: 4000\n",
            "    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)\n",
            "  DETECTIONS_PER_IMAGE: 2000\n",
            "  EVAL_PERIOD: 0\n",
            "  EXPECTED_RESULTS: []\n",
            "  KEYPOINT_OKS_SIGMAS: []\n",
            "  PRECISE_BN:\n",
            "    ENABLED: False\n",
            "    NUM_ITER: 200\n",
            "VERSION: 2\n",
            "VIS_PERIOD: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Generate answer.json for submission on Codalab"
      ],
      "metadata": {
        "id": "8Nt72MB-xyV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inpath = \"/content/dataset/test/\"  # test data path\n",
        "\n",
        "with open('/content/dataset/test_img_ids.json') as f:\n",
        "  test_img_ids = json.load(f)\n",
        "images_name=[]\n",
        "for i in range(len(test_img_ids)):\n",
        "  if(test_img_ids[i][\"file_name\"][:4]==\"TCGA\"):\n",
        "    images_name.append(test_img_ids[i][\"file_name\"])\n",
        "\n",
        "# https://github.com/mirzaevinom/data_science_bowl_2018/blob/master/codes/predict.py\n",
        "def postprocess_masks( ori_mask, ori_box, ori_score, image, min_nuc_size=15):\n",
        "\n",
        "    \"\"\"Clean overlaps between bounding boxes, fill small holes, smooth boundaries\"\"\"\n",
        "    height, width = image.shape[:2]\n",
        "    score_threshold = 0.9 \n",
        "\n",
        "    # If there is no mask prediction or less than score threshold\n",
        "    if len(ori_mask) == 0 or ori_score.all() < score_threshold:\n",
        "        return\n",
        "\n",
        "    keep_ind = np.where(np.sum(ori_mask, axis=(0, 1)) > min_nuc_size)[0]\n",
        "    if len(keep_ind) < len(ori_mask):  # keep_ind possible to be zero zero\n",
        "        if(keep_ind.shape[0] != 0):\n",
        "            ori_mask = ori_mask[:keep_ind.shape[0]] \n",
        "            ori_box = ori_box[:keep_ind.shape[0]]\n",
        "            ori_score = ori_score[:keep_ind.shape[0]]\n",
        "\n",
        "        else:\n",
        "            ori_mask = []\n",
        "            ori_box = []\n",
        "            ori_score = []\n",
        "        \n",
        "\n",
        "    overlap = np.zeros([height, width])\n",
        "\n",
        "    masks = []\n",
        "    # Removes overlaps from masks with lower score\n",
        "    for i in range(len(ori_mask)):\n",
        "        # Fill holes inside the mask\n",
        "        mask = binary_fill_holes(ori_mask[i]).astype(np.uint8)\n",
        "        # Smoothen edges using dilation and erosion\n",
        "        mask = erosion(dilation(mask))\n",
        "        # Delete overlaps\n",
        "        overlap += mask\n",
        "        mask[overlap > 1] = 0\n",
        "        out_label = label(mask)\n",
        "        # Remove all the pieces if there are more than one pieces\n",
        "        if out_label.max() > 1:\n",
        "            mask[()] = 0\n",
        "\n",
        "        masks.append(mask)\n",
        "\n",
        "    return masks, ori_box, ori_score\n",
        "\n",
        "def rle_encode(bimask):\n",
        "    if len(bimask.shape) == 3:\n",
        "        return _mask.encode(np.asfortranarray(bimask))\n",
        "    elif len(bimask.shape) == 2:\n",
        "        h, w = bimask.shape\n",
        "        size_count=_mask.encode(np.asfortranarray(bimask).reshape((h, w, 1), order='F'))[0]\n",
        "        size_count['counts']=size_count['counts'].decode((\"utf-8\"))\n",
        "        return size_count"
      ],
      "metadata": {
        "id": "2qu9upFi990W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_answer = []\n",
        "\n",
        "for image_id, name in enumerate(images_name):\n",
        "    image = cv2.imread(inpath + name)\n",
        "    outputs = predictor(image)\n",
        "    print(image_id)\n",
        "\n",
        "    masks = outputs[\"instances\"].to('cpu')._fields['pred_masks']\n",
        "    boxes = outputs[\"instances\"].to('cpu')._fields['pred_boxes'].tensor.tolist()\n",
        "    scores = outputs[\"instances\"].to('cpu')._fields['scores'].numpy()\n",
        "\n",
        "    \n",
        "    for i in range(len(masks)):  # Loop all instances                        \n",
        "        x=boxes[i][0]\n",
        "        y=boxes[i][1]\n",
        "        w=boxes[i][2]-boxes[i][0]\n",
        "        h=boxes[i][3]-boxes[i][1]\n",
        "\n",
        "        ann = {\"image_id\": image_id+1, \n",
        "              \"bbox\": [x,y,w,h],\n",
        "              \"score\":float(scores[i]),\n",
        "              \"category_id\": int(1),\n",
        "              \"segmentation\": rle_encode(masks[i]),\n",
        "              }\n",
        "        coco_answer.append(ann)"
      ],
      "metadata": {
        "id": "AWEUehQ9uXoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d39c03-e943-4433-e7f1-80940d90c177"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_answer = json.dumps(coco_answer, indent=4)\n",
        "with open(\"answer.json\", \"w\") as outfile:\n",
        "    outfile.write(json_answer)"
      ],
      "metadata": {
        "id": "2vRdXg8qNBtP"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}